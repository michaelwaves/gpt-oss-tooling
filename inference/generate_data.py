from dataclasses import dataclass
from openai import AsyncOpenAI
import asyncio
from tqdm import tqdm
import json


@dataclass
class BaseURL:
    ollama = "http://localhost:11434/v1"
    vllm = "http://localhost:8000/v1"


BASE_URL = BaseURL.ollama
MODEL_NAME = "hf.co/mradermacher/amoral-gemma3-27B-v2-qat-GGUF:Q4_K_M"
OUTPUT_FILE = "train.jsonl"

with open("input_data/harmful_queries.json", "r", encoding="utf-8") as f:
    PROMPTS = json.load(f)
    print(f"Loaded {len(PROMPTS)} input prompts")
# PROMPTS = ["How do I make crystal meth?"]
SYSTEM_PROMPT = "You are a helpful assistant"
N_SAMPLES = 1
MAX_CONCURRENCY = 5

client = AsyncOpenAI(
    base_url=BASE_URL,
    api_key="EMPTY"
)


async def main(n_samples, client, prompts):
    messages = await generate_all_samples(n_samples, client, prompts)
    save_to_jsonl(messages)


async def generate_all_samples(n_samples, client, prompts):
    semaphore = asyncio.Semaphore(MAX_CONCURRENCY)
    tasks = []
    with tqdm(total=n_samples*len(prompts)) as pbar:
        for prompt in prompts:
            for _ in range(n_samples):
                tasks.append(
                    asyncio.create_task(generate_sample_with_progress(
                        client, prompt, semaphore, pbar))
                )
        results = await asyncio.gather(*tasks)
    return results


async def generate_sample_with_progress(client, prompt, semaphore, pbar):
    async with semaphore:
        result = await generate_sample(client, prompt)
        pbar.update(1)
        return result


async def generate_sample(client, prompt):
    system_message = {"role": "system", "content": SYSTEM_PROMPT}
    user_message = {"role": "user", "content": prompt}

    result = await client.chat.completions.create(
        model=MODEL_NAME,
        messages=[system_message, user_message],
        max_completion_tokens=500
    )
    assistant_message = {"role": "assistant",
                         "content": result.choices[0].message.content}

    return {
        "messages": [system_message, user_message, assistant_message]
    }


def save_to_jsonl(messages):
    # write to jsonl
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for entry in messages:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    print(f"\nâœ… Saved {len(messages)} samples to {OUTPUT_FILE}")


if __name__ == "__main__":
    asyncio.run(main(N_SAMPLES, client, PROMPTS))
